# 文本与字节序列

## 字符问题

Unicode 标准把字符的标识和具体的字节表述进行了如下的明确区分：

- 字符的标识，即码位，目前的Unicode字符分为17组编排，0x0000 至 0x10FFFF，每组称为平面（Plane），而每平面拥有65536个码位，共1114112个。以4~6个十六进制数字表示，而且加前缀“U+”。例如：字母 A 的码位是 U+0041
- 字符的具体表述取决于所用的编码。编码是码位和字节序列之间转换时使用的算法。例如：在 UTF-8 编码中，A（U+0041）的码位编码成单个字节 \x41，而在 UTF-16LE 编码中编码成两个字节\x41\x00

把码位转换成字节序列的过程是编码；把字节序列转换成码位的过程是解码。

```python
In [1]: s = 'café'

In [2]: len(s)
Out[2]: 4

In [3]: b = s.encode('utf8')		# 使用 UTF-8 把 str 对象编码成 bytes 对象

In [4]: b
Out[4]: b'caf\xc3\xa9'				# 字节序列 b 有 5 个字节（UTF-8 中，“é” 的码位编码成两个字节）

In [5]: len(b)
Out[5]: 5

In [6]: b.decode('utf8')
Out[6]: 'café'
```

### 字节概要

Python 内置了两种基本的二进制序列类型：Python 3 引入的不可变 bytes 类型和 Python 2.6 添加的可变 bytearray 类型。bytes 或 bytearray 对象的各个元素是介于 0~255（含）之间的整数，二进制序列的切片始终是同一类型的二进制序列，包括长度为 1 的切片

### 编解码问题

- UnicodeEncodeError（把字符串转换成二进制序列时）

```python
IIn [42]: city = 'São Paulo'

In [43]: city.encode('utf-8')
Out[43]: b'S\xc3\xa3o Paulo'

In [44]: city.encode('cp437')	# 'cp437' 无法编码 'ã'（带波形符的“a”）。默认的错误处理方式
							  # 'strict' 抛出 UnicodeEncodeError。
---------------------------------------------------------------------------
UnicodeEncodeError                        Traceback (most recent call last)
<ipython-input-44-064a572fd5b6> in <module>
----> 1 city.encode('cp437')

d:\dev\python36\lib\encodings\cp437.py in encode(self, input, errors)
     10
     11     def encode(self,input,errors='strict'):
---> 12         return codecs.charmap_encode(input,errors,encoding_map)
     13
     14     def decode(self,input,errors='strict'):

UnicodeEncodeError: 'charmap' codec can't encode character '\xe3' in position 1: character maps to <undefined>

In [45]: city.encode('cp437', errors='ignore')		# 跳过无法编码的字符
Out[45]: b'So Paulo'

In [46]: city.encode('cp437', errors='replace')		# 把无法编码的字符替换成 '?'
Out[46]: b'S?o Paulo'
    
```

- UnicodeDecodeError（把二进制序列转换成字符串时）

```python
In [49]: octets = b'Montr\xe9al'

In [50]: octets.decode('cp1252')
Out[50]: 'Montréal'

In [51]: octets.decode('koi8_r')
Out[51]: 'MontrИal'

In [52]: octets.decode('utf-8')
---------------------------------------------------------------------------
UnicodeDecodeError                        Traceback (most recent call last)
<ipython-input-52-15cc3c10775a> in <module>
----> 1 octets.decode('utf-8')

UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 5: invalid continuation byte

In [53]: octets.decode('utf-8', errors='replace')
Out[53]: 'Montr�al'
```

### BOM：鬼符

有时候在 UTF-16 的编码的序列开头有几个额外的字符，如下：

```python
IIn [54]: u16 = 'El Niño'.encode('utf-16')

In [55]: u16
Out[55]: b'\xff\xfeE\x00l\x00 \x00N\x00i\x00\xf1\x00o\x00'
```

```'\xff\xfeE'```这个就是 BOM，即字节序标记（byte-ordermark），指明编码时使用 Intel CPU 的小字节序。

```python
IIn [56]: u16le = 'El Niño'.encode('utf_16le')

IIn [57]: u16be = 'El Niño'.encode('utf_16be')

In [58]: list(u16le)
Out[58]: [69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111, 0]

In [59]: list(u16be)
Out[59]: [0, 69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111]
```

如果有 BOM，UTF-16 编解码器会将其过滤掉，为你提供没有前导ZERO WIDTH NO-BREAK SPACE 字符的真正文本。根据标准，如果文件使用 UTF-16 编码，而且没有 BOM，那么应该假定它使用的是 UTF-16BE（大字节序）编码。然而，Intel x86 架构用的是小字节序，因此有很多文件用的是不带 BOM 的小字节序 UTF-16 编码。

UTF-8 的一大优势是，不管设备使用哪种字节序，生成的字节序列始终一致，因此不需要 BOM。

## 规范化 Unicode 字符

```python
>>> s1 = 'café'
>>> s2 = 'cafe\u0301'    # U+0301 是 COMBINING ACUTE ACCENT，加在“e”后面得							到“é”。在Unicode 标准中，'é' 和 'e\u0301' 这样						 的序列叫“标准等物”（canonical equivalent）
>>> s1, s2
('café', 'café')
>>> len(s1), len(s2)
(4, 5)
>>> s1 == s2			# 但是 Python 是根据码位判定两者不相等
False
```

因为 Unicode 有组合字符（变音符号和附加到前一个字符上的记号，打印时作为一个整体），所以字符串比较起来很复杂。

解决这个问题是使用 ```unicodedata.normalize```函数提供的 Unicode 规范化。这函数一个参数是这四者之一：'NFC'、'NFD'、'NFKC' 和 'NFKD'

```python
>>> from unicodedata import normalize
>>> s1 = 'café' # 把"e"和重音符组合在一起
>>> s2 = 'cafe\u0301' # 分解成"e"和重音符
>>> len(s1), len(s2)
(4, 5)
>>> len(normalize('NFC', s1)), len(normalize('NFC', s2))	
(4, 4)	# NFC 使用最少的码位构成等价的字符串
>>> len(normalize('NFD', s1)), len(normalize('NFD', s2))
(5, 5)	# NFD 把组合字符分解成基字符和单独的组合字符
>>> normalize('NFC', s1) == normalize('NFC', s2)
True
>>> normalize('NFD', s1) == normalize('NFD', s2)
True
```

在另外两个规范化形式（NFKC 和 NFKD）的首字母缩略词中，字母 K 表示 ‘compatibility’ （兼容性）。

```python
>>> from unicodedata import normalize, name
>>> half = '½'
>>> normalize('NFKC', half)
'1⁄2'
>>> four_squared = '4²'
>>> normalize('NFKC', four_squared)
'42'
>>> micro = 'μ'
>>> micro_kc = normalize('NFKC', micro)
>>> micro, micro_kc
('μ', 'μ')
>>> ord(micro), ord(micro_kc)
(181, 956)
>>> name(micro), name(micro_kc)
('MICRO SIGN', 'GREEK SMALL LETTER MU')
```

使用 NFKC 和 NFKD 规范化形式时要小心，而且只能在特殊情况中使用，例如搜索和索引，而不能用于持久存储，因为这两种转换会导致数据损失。

